{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866d53c9",
   "metadata": {},
   "source": [
    "\n",
    "Clustering & Fitting Assignment\n",
    "\n",
    "Reads:  owid-co2-data.csv\n",
    "\n",
    "Writes: outputs/ (plots, CSVs, metrics, short assessment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d0f89",
   "metadata": {},
   "source": [
    "#### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d195254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccea481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- Config ----------------\n",
    "DATA_PATH = \"owid-co2-data.csv\"   # uploaded dataset path\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a5a2e",
   "metadata": {},
   "source": [
    "#### Load and inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8c5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: owid-co2-data.csv\n",
      "Raw shape: (25204, 58)\n",
      "Columns: ['iso_code', 'country', 'year', 'co2', 'consumption_co2', 'co2_growth_prct', 'co2_growth_abs', 'trade_co2', 'co2_per_capita', 'consumption_co2_per_capita', 'share_global_co2', 'cumulative_co2', 'share_global_cumulative_co2', 'co2_per_gdp', 'consumption_co2_per_gdp', 'co2_per_unit_energy', 'coal_co2', 'cement_co2', 'flaring_co2', 'gas_co2', 'oil_co2', 'other_industry_co2', 'cement_co2_per_capita', 'coal_co2_per_capita', 'flaring_co2_per_capita', 'gas_co2_per_capita', 'oil_co2_per_capita', 'other_co2_per_capita', 'trade_co2_share', 'share_global_cement_co2', 'share_global_coal_co2', 'share_global_flaring_co2', 'share_global_gas_co2', 'share_global_oil_co2', 'share_global_other_co2', 'cumulative_cement_co2', 'cumulative_coal_co2', 'cumulative_flaring_co2', 'cumulative_gas_co2', 'cumulative_oil_co2', 'cumulative_other_co2', 'share_global_cumulative_cement_co2', 'share_global_cumulative_coal_co2', 'share_global_cumulative_flaring_co2', 'share_global_cumulative_gas_co2', 'share_global_cumulative_oil_co2', 'share_global_cumulative_other_co2', 'total_ghg', 'ghg_per_capita', 'methane', 'methane_per_capita', 'nitrous_oxide', 'nitrous_oxide_per_capita', 'population', 'gdp', 'primary_energy_consumption', 'energy_per_capita', 'energy_per_gdp']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- 1. Load and inspect dataset ----------------\n",
    "print(\"Loading dataset from:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675f551",
   "metadata": {},
   "source": [
    "#### Filter data (1990-2019) and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e08e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered shape (1990-2019, with co2_per_capita): (6401, 16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 2. Filter data (1990-2019) and clean ----------------\n",
    "YEARS = list(range(1990, 2020))\n",
    "if \"year\" in df.columns:\n",
    "    df = df[df[\"year\"].isin(YEARS)].copy()\n",
    "else:\n",
    "    raise RuntimeError(\"'year' column not found in dataset.\")\n",
    "\n",
    "# Remove OWID aggregates if present\n",
    "if \"iso_code\" in df.columns:\n",
    "    df = df[~df[\"iso_code\"].isna()]\n",
    "    df = df[~df[\"iso_code\"].astype(str).str.startswith(\"OWID_\")]\n",
    "\n",
    "# Select commonly-used columns that we will reference; only keep those present\n",
    "wanted = [\n",
    "    \"iso_code\", \"country\", \"year\",\n",
    "    \"co2\", \"co2_per_capita\", \"consumption_co2\", \"consumption_co2_per_capita\",\n",
    "    \"population\", \"gdp\", \"total_ghg\", \"ghg_per_capita\",\n",
    "    \"methane\", \"nitrous_oxide\", \"primary_energy_consumption\",\n",
    "    \"energy_per_capita\", \"energy_per_gdp\"\n",
    "]\n",
    "available = [c for c in wanted if c in df.columns]\n",
    "df = df[available].copy()\n",
    "# require co2_per_capita for analyses\n",
    "if \"co2_per_capita\" not in df.columns:\n",
    "    raise RuntimeError(\"co2_per_capita column not found. Cannot continue.\")\n",
    "\n",
    "df = df.dropna(subset=[\"co2_per_capita\"]).reset_index(drop=True)\n",
    "print(\"Filtered shape (1990-2019, with co2_per_capita):\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2a2f0",
   "metadata": {},
   "source": [
    "#### Compute country-level moments (four main moments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486ffea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved country-level moments -> outputs\\country_moments.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 3. Compute country-level moments (four main moments) ----------------\n",
    "# We'll group by iso_code (if available) and country\n",
    "group_cols = [\"iso_code\", \"country\"] if \"iso_code\" in df.columns else [\"country\"]\n",
    "grouped = df.groupby(group_cols, dropna=False)\n",
    "\n",
    "def compute_moments(series):\n",
    "    arr = series.dropna().values\n",
    "    n = len(arr)\n",
    "    if n == 0:\n",
    "        return pd.Series({\n",
    "            \"count\": 0, \"mean_co2pc\": np.nan, \"var_co2pc\": np.nan,\n",
    "            \"std_co2pc\": np.nan, \"skew_co2pc\": np.nan, \"kurt_co2pc\": np.nan\n",
    "        })\n",
    "    mean = float(arr.mean())\n",
    "    var = float(arr.var(ddof=0))        # population variance\n",
    "    std = float(arr.std(ddof=1)) if n > 1 else 0.0\n",
    "    skew = float(stats.skew(arr, bias=False)) if n > 2 else np.nan\n",
    "    kurt = float(stats.kurtosis(arr, fisher=True, bias=False)) if n > 3 else np.nan\n",
    "    return pd.Series({\n",
    "        \"count\": n, \"mean_co2pc\": mean, \"var_co2pc\": var,\n",
    "        \"std_co2pc\": std, \"skew_co2pc\": skew, \"kurt_co2pc\": kurt\n",
    "    })\n",
    "\n",
    "country_stats = grouped[\"co2_per_capita\"].apply(compute_moments).reset_index()\n",
    "# if gdp present, compute mean gdp per country for clustering\n",
    "if \"gdp\" in df.columns:\n",
    "    gdp_mean = grouped[\"gdp\"].mean().reset_index().rename(columns={\"gdp\": \"mean_gdp\"})\n",
    "    country_stats = country_stats.merge(gdp_mean, on=group_cols, how=\"left\")\n",
    "\n",
    "country_stats.to_csv(os.path.join(OUT_DIR, \"country_moments.csv\"), index=False)\n",
    "print(\"Saved country-level moments ->\", os.path.join(OUT_DIR, \"country_moments.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad6ddb",
   "metadata": {},
   "source": [
    "#### Plots (relational, categorical, statistical) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f406d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 snapshot shape (or last available): (214, 16)\n",
      "Saved relational plot -> relational_gdp_vs_co2_2019.png\n",
      "Saved categorical plot -> categorical_top10_co2_2019.png\n",
      "Saved heatmap -> heatmap_2019.png\n",
      "Skipping GDP-decile boxplot: not enough distinct GDP values.\n",
      "Missing moment columns: ['mean_co2pc', 'std_co2pc', 'skew_co2pc', 'kurt_co2pc']  — attempting alternative aggregation.\n",
      "Saved pairplot -> pairplot_moments.png\n",
      "Saved descriptive stats -> descriptive_co2_per_capita.txt\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 4. Plots (relational, categorical, statistical) ----------------\n",
    "# Create a snapshot for 2019 if possible, else use the latest available per country\n",
    "df2019 = df[df[\"year\"] == 2019].copy()\n",
    "if df2019.empty:\n",
    "    # fallback: last available record per country\n",
    "    last_year = df.groupby(group_cols)[\"year\"].transform(\"max\")\n",
    "    df2019 = df[df[\"year\"] == last_year].copy()\n",
    "print(\"2019 snapshot shape (or last available):\", df2019.shape)\n",
    "\n",
    "# 4a Relational plot: GDP vs CO2 per capita (scatter + regression)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if \"gdp\" in df2019.columns and df2019[\"gdp\"].notna().sum() >= 5:\n",
    "    # log transform to reduce skew\n",
    "    sns.regplot(x=np.log1p(df2019[\"gdp\"]), y=df2019[\"co2_per_capita\"],\n",
    "                scatter_kws={\"alpha\": 0.6}, line_kws={\"color\":\"red\"})\n",
    "    plt.xlabel(\"log(1 + GDP) (2019)\")\n",
    "else:\n",
    "    # no reliable GDP, use index on x-axis\n",
    "    sns.regplot(x=np.arange(len(df2019)), y=df2019[\"co2_per_capita\"], scatter_kws={\"alpha\": 0.6})\n",
    "    plt.xlabel(\"Country index\")\n",
    "plt.ylabel(\"CO2 per capita\")\n",
    "plt.title(\"Relational: GDP vs CO2 per capita (2019 snapshot)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"relational_gdp_vs_co2_2019.png\"))\n",
    "plt.close()\n",
    "print(\"Saved relational plot -> relational_gdp_vs_co2_2019.png\")\n",
    "\n",
    "# 4b Categorical plot: Top-10 countries by total CO2 (2019)\n",
    "if \"co2\" in df2019.columns:\n",
    "    top10 = df2019[[\"country\", \"co2\"]].dropna().sort_values(\"co2\", ascending=False).head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=top10, x=\"co2\", y=\"country\")\n",
    "    plt.xlabel(\"Total CO2 (2019)\")\n",
    "    plt.title(\"Top 10 countries by total CO2 (2019)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"categorical_top10_co2_2019.png\"))\n",
    "    plt.close()\n",
    "    print(\"Saved categorical plot -> categorical_top10_co2_2019.png\")\n",
    "else:\n",
    "    # fallback categorical: top by co2_per_capita\n",
    "    top10 = df2019[[\"country\", \"co2_per_capita\"]].dropna().sort_values(\"co2_per_capita\", ascending=False).head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=top10, x=\"co2_per_capita\", y=\"country\")\n",
    "    plt.xlabel(\"CO2 per capita (2019)\")\n",
    "    plt.title(\"Top 10 countries by CO2 per capita (2019)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"categorical_top10_co2pc_2019.png\"))\n",
    "    plt.close()\n",
    "    print(\"Saved categorical plot -> categorical_top10_co2pc_2019.png\")\n",
    "\n",
    "# 4c Statistical plots:\n",
    "# Correlation heatmap for numeric features present\n",
    "numeric_candidates = [\"co2_per_capita\", \"gdp\", \"population\", \"co2\", \"total_ghg\", \"ghg_per_capita\"]\n",
    "num_cols = [c for c in numeric_candidates if c in df2019.columns]\n",
    "if len(num_cols) >= 2:\n",
    "    corr = df2019[num_cols].corr()\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation heatmap (2019 snapshot)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"heatmap_2019.png\"))\n",
    "    plt.close()\n",
    "    print(\"Saved heatmap -> heatmap_2019.png\")\n",
    "else:\n",
    "    print(\"Not enough numeric columns for heatmap. Skipping.\")\n",
    "\n",
    "# Boxplot: use GDP-deciles as a categorical grouping if GDP is usable\n",
    "if \"gdp\" in df2019.columns and df2019[\"gdp\"].notna().sum() >= 10 and df2019[\"gdp\"].nunique() >= 10:\n",
    "    # build deciles from rank to avoid ties causing qcut failure; duplicates='drop' is extra safety\n",
    "    try:\n",
    "        # work on a copy\n",
    "        df2019_cp = df2019.copy()\n",
    "        df2019_cp[\"gdp_decile\"] = pd.qcut(df2019_cp[\"gdp\"].rank(method=\"first\"),\n",
    "                                          q=10, labels=False, duplicates=\"drop\") + 1\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df2019_cp.dropna(subset=[\"gdp_decile\"]), x=\"gdp_decile\", y=\"co2_per_capita\")\n",
    "        plt.xlabel(\"GDP decile (1 = lowest)\")\n",
    "        plt.title(\"CO2 per capita by GDP decile (2019)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, \"boxplot_co2_by_gdp_decile_2019.png\"))\n",
    "        plt.close()\n",
    "        print(\"Saved boxplot -> boxplot_co2_by_gdp_decile_2019.png\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not create GDP-decile boxplot (qcut issue):\", str(e))\n",
    "else:\n",
    "    print(\"Skipping GDP-decile boxplot: not enough distinct GDP values.\")\n",
    "\n",
    "# Pairplot of the four moments (safe)\n",
    "moment_cols = [\"mean_co2pc\", \"std_co2pc\", \"skew_co2pc\", \"kurt_co2pc\"]\n",
    "missing_moments = [c for c in moment_cols if c not in country_stats.columns]\n",
    "if missing_moments:\n",
    "    # Try to compute simpler moments (fallback)\n",
    "    print(\"Missing moment columns:\", missing_moments, \" — attempting alternative aggregation.\")\n",
    "    # compute using agg shortcuts\n",
    "    fallback = df.groupby(group_cols)[\"co2_per_capita\"].agg(\n",
    "        mean_co2pc=\"mean\", std_co2pc=\"std\"\n",
    "    ).reset_index()\n",
    "    # compute skew & kurt per-country using apply where possible\n",
    "    if \"skew_co2pc\" not in fallback.columns:\n",
    "        skew = df.groupby(group_cols)[\"co2_per_capita\"].apply(lambda x: float(stats.skew(x.dropna(), bias=False)) if len(x.dropna())>2 else np.nan).reset_index(name=\"skew_co2pc\")\n",
    "        kurt = df.groupby(group_cols)[\"co2_per_capita\"].apply(lambda x: float(stats.kurtosis(x.dropna(), fisher=True, bias=False)) if len(x.dropna())>3 else np.nan).reset_index(name=\"kurt_co2pc\")\n",
    "        fallback = fallback.merge(skew, on=group_cols, how=\"left\").merge(kurt, on=group_cols, how=\"left\")\n",
    "    pair_df = fallback[[\"mean_co2pc\", \"std_co2pc\", \"skew_co2pc\", \"kurt_co2pc\"]].dropna()\n",
    "else:\n",
    "    pair_df = country_stats[moment_cols].dropna()\n",
    "\n",
    "if len(pair_df) > 1:\n",
    "    sample = pair_df.sample(min(200, len(pair_df)), random_state=RANDOM_STATE)\n",
    "    try:\n",
    "        sns.pairplot(sample)\n",
    "        plt.suptitle(\"Pairplot: Moments of CO2 per capita (sample)\", y=1.02)\n",
    "        plt.savefig(os.path.join(OUT_DIR, \"pairplot_moments.png\"))\n",
    "        plt.close()\n",
    "        print(\"Saved pairplot -> pairplot_moments.png\")\n",
    "    except Exception as e:\n",
    "        print(\"Pairplot failed:\", e)\n",
    "else:\n",
    "    print(\"Not enough country-moment rows to produce a pairplot. Skipping.\")\n",
    "\n",
    "# Save a descriptive summary for co2_per_capita\n",
    "desc = df[\"co2_per_capita\"].describe()\n",
    "with open(os.path.join(OUT_DIR, \"descriptive_co2_per_capita.txt\"), \"w\") as fh:\n",
    "    fh.write(str(desc))\n",
    "print(\"Saved descriptive stats -> descriptive_co2_per_capita.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f538659",
   "metadata": {},
   "source": [
    "####  Clustering (KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03096e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing clustering columns: ['mean_co2pc', 'std_co2pc'] — clustering will proceed with available features: ['mean_gdp']\n",
      "Saved elbow plot -> kmeans_elbow.png\n",
      "Saved cluster assignments -> outputs\\country_clusters_kmeans.csv (best_k=2)\n",
      "Skipping PCA: not enough rows or features for 2D projection.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 5. Clustering (KMeans) ----------------\n",
    "# Prepare features: mean_co2pc, std_co2pc, optionally mean_gdp\n",
    "cluster_cols = [c for c in [\"mean_co2pc\", \"std_co2pc\", \"mean_gdp\"] if c in country_stats.columns]\n",
    "\n",
    "if not cluster_cols:\n",
    "    print(\"No clustering features available (mean_co2pc, std_co2pc, mean_gdp missing). Skipping clustering.\")\n",
    "else:\n",
    "    cluster_df = country_stats.copy()\n",
    "    # Report missing columns if any\n",
    "    missing_cols = [c for c in [\"mean_co2pc\", \"std_co2pc\", \"mean_gdp\"] if c not in cluster_df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Missing clustering columns: {missing_cols} — clustering will proceed with available features: {cluster_cols}\")\n",
    "\n",
    "    # Drop rows with missing clustering values\n",
    "    cluster_df_num = cluster_df.dropna(subset=cluster_cols)\n",
    "    if cluster_df_num.empty:\n",
    "        print(\"No countries with complete clustering features — skipping clustering.\")\n",
    "    else:\n",
    "        cluster_df_num = cluster_df_num.set_index(group_cols)\n",
    "        X = cluster_df_num[cluster_cols].values\n",
    "\n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Elbow plot\n",
    "        inertia = []\n",
    "        Ks = list(range(1, 11))\n",
    "        for k in Ks:\n",
    "            km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "            km.fit(X_scaled)\n",
    "            inertia.append(km.inertia_)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(Ks, inertia, \"-o\")\n",
    "        plt.xlabel(\"k\")\n",
    "        plt.ylabel(\"Inertia\")\n",
    "        plt.title(\"Elbow plot for KMeans (country-level features)\")\n",
    "        plt.xticks(Ks)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, \"kmeans_elbow.png\"))\n",
    "        plt.close()\n",
    "        print(\"Saved elbow plot -> kmeans_elbow.png\")\n",
    "\n",
    "        # Silhouette scores for k=2..6\n",
    "        sil_scores = {}\n",
    "        for k in range(2, 7):\n",
    "            km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "            labels = km.fit_predict(X_scaled)\n",
    "            sil_scores[k] = silhouette_score(X_scaled, labels)\n",
    "        best_k = max(sil_scores, key=sil_scores.get)\n",
    "\n",
    "        # Final KMeans with best k\n",
    "        km = KMeans(n_clusters=best_k, random_state=RANDOM_STATE, n_init=20)\n",
    "        labels = km.fit_predict(X_scaled)\n",
    "        cluster_df_num[\"kmeans_cluster\"] = labels\n",
    "\n",
    "        cluster_assignments_path = os.path.join(OUT_DIR, \"country_clusters_kmeans.csv\")\n",
    "        cluster_df_num.reset_index().to_csv(cluster_assignments_path, index=False)\n",
    "        print(f\"Saved cluster assignments -> {cluster_assignments_path} (best_k={best_k})\")\n",
    "\n",
    "        # PCA projection visualization (only if enough samples/features)\n",
    "        if cluster_df_num.shape[0] > 1 and len(cluster_cols) > 1:\n",
    "            pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "            proj = pca.fit_transform(X_scaled)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.scatterplot(\n",
    "                x=proj[:, 0], y=proj[:, 1],\n",
    "                hue=labels,\n",
    "                palette=sns.color_palette(n_colors=best_k),\n",
    "                s=60\n",
    "            )\n",
    "            plt.title(f\"KMeans clusters (k={best_k}) projected to 2D (PCA)\")\n",
    "            plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_DIR, f\"kmeans_k{best_k}_pca.png\"))\n",
    "            plt.close()\n",
    "            print(f\"Saved PCA cluster plot -> kmeans_k{best_k}_pca.png\")\n",
    "        else:\n",
    "            print(\"Skipping PCA: not enough rows or features for 2D projection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77149e",
   "metadata": {},
   "source": [
    "#### Fitting (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3042f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved regression metrics -> outputs\\regression_metrics.txt\n",
      "Saved regression plot -> regression_actual_vs_predicted_ridge.png\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 6. Fitting (Regression) ----------------\n",
    "# Predict co2_per_capita from log(GDP) and log(population) using 2010-2019 rows\n",
    "fit_df = df[(df[\"year\"] >= 2010) & (df[\"year\"] <= 2019)].dropna(subset=[\"co2_per_capita\"]).copy()\n",
    "reg_metrics_path = os.path.join(OUT_DIR, \"regression_metrics.txt\")\n",
    "\n",
    "if (\"gdp\" in fit_df.columns) and (\"population\" in fit_df.columns) and (fit_df[[\"gdp\", \"population\"]].dropna().shape[0] > 10):\n",
    "    fit_df = fit_df.dropna(subset=[\"gdp\", \"population\"])\n",
    "    fit_df[\"log_gdp\"] = np.log1p(fit_df[\"gdp\"])\n",
    "    fit_df[\"log_pop\"] = np.log1p(fit_df[\"population\"])\n",
    "    Xr = fit_df[[\"log_gdp\", \"log_pop\"]].values\n",
    "    yr = fit_df[\"co2_per_capita\"].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xr, yr, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "    lr_metrics = metrics(y_test, y_pred_lr)\n",
    "    ridge_metrics = metrics(y_test, y_pred_ridge)\n",
    "\n",
    "    with open(reg_metrics_path, \"w\") as fh:\n",
    "        fh.write(\"Linear Regression metrics:\\n\")\n",
    "        fh.write(str(lr_metrics) + \"\\n\\n\")\n",
    "        fh.write(\"Ridge Regression metrics:\\n\")\n",
    "        fh.write(str(ridge_metrics) + \"\\n\")\n",
    "\n",
    "    # plot actual vs predicted (Ridge)\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.scatter(y_test, y_pred_ridge, alpha=0.6)\n",
    "    mn = min(np.nanmin(y_test), np.nanmin(y_pred_ridge))\n",
    "    mx = max(np.nanmax(y_test), np.nanmax(y_pred_ridge))\n",
    "    plt.plot([mn, mx], [mn, mx], \"r--\")\n",
    "    plt.xlabel(\"Actual CO2 per capita\")\n",
    "    plt.ylabel(\"Predicted CO2 per capita (Ridge)\")\n",
    "    plt.title(\"Actual vs Predicted CO2 per capita (Ridge)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"regression_actual_vs_predicted_ridge.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved regression metrics ->\", reg_metrics_path)\n",
    "    print(\"Saved regression plot -> regression_actual_vs_predicted_ridge.png\")\n",
    "else:\n",
    "    with open(reg_metrics_path, \"w\") as fh:\n",
    "        fh.write(\"Not enough data to run regression (missing gdp or population or insufficient rows)\\n\")\n",
    "    print(\"Regression skipped: insufficient data (gdp/population). Metrics file written stating skip.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf0e8e",
   "metadata": {},
   "source": [
    "#### Short assessment saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41284e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved short assessment -> assessment.txt\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 7. Short assessment saved ----------------\n",
    "with open(os.path.join(OUT_DIR, \"assessment.txt\"), \"w\") as fh:\n",
    "    fh.write(\"Clustering & Fitting Assignment - Short assessment\\n\\n\")\n",
    "    fh.write(\"- Dataset: uploaded OWID CO2 CSV filtered to 1990-2019.\\n\")\n",
    "    fh.write(\"- Computed per-country four main moments for co2_per_capita and saved to country_moments.csv.\\n\")\n",
    "    fh.write(\"- Created relational (GDP vs CO2pc), categorical (top-10 CO2), and statistical plots (heatmap, boxplot by GDP-decile where possible, pairplot sample).\\n\")\n",
    "    fh.write(\"- Performed KMeans clustering on country-level statistics; selected k by silhouette score and saved assignments.\\n\")\n",
    "    fh.write(\"- Fitted LinearRegression and Ridge to predict CO2 per capita from log(GDP) and log(population) for 2010-2019; metrics saved.\\n\")\n",
    "    fh.write(\"\\nLimitations:\\n- No continent column in uploaded data; used GDP-deciles as categorical grouping for boxplot.\\n- Missing values reduce sample size for some countries and analyses.\\n\")\n",
    "print(\"Saved short assessment -> assessment.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20084e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
